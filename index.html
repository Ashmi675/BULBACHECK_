<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BULBACHECK</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            overflow: hidden;
        }
        .bg-video {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            z-index: -1;
        }
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #7dc186;
        }
        header {
            background: #4fa7ab;
            color: #ffe1e1;
            padding: 10px 0;
            text-align: center;
        }
        nav {
            margin: 20px 0;
        }
        nav a {
            margin: 0 15px;
            color: #ffdede;
            text-decoration: none;
        }
        .container {
            width: 80%;
            margin: auto;
            overflow: hidden;
        }
        .news-block {
            background: #a4bd71;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        .news-block h2 {
            margin-top: 0;
        }
        footer {
            text-align: center;
            padding: 10px 0;
            background: #73a0b1;
            color: #fff;
            position: relative;
            bottom: 0;
            width: 100%;
        }
        .home-message{
            text-align: center;
            color: brown;
            position: relative;
        }
        .about-message{
            text-align: center;
            color: rgb(205, 96, 28);
            position: relative;
        }
        .uploading{
            text-align: center;
            color: white;
        }
        #message{
            color: white;
            size: 100px;
            height: 1000%;
        }
        
    </style>
</head>
<body>
    <video class="bg-video" autoplay muted loop playsinline>
        <source src="/assets/your-video-file.mp4" type="video/mp4">
        Your browser does not support HTML5 video.
    </video>
    
<div class="content">
<header>
    <div class="title-background">
        <h1>BULBACHECK</h1>
    </div>
    <nav>
        <a href="#home" >Home</a>
        <a href="#about">About</a>
        <a href="#news">News</a>
        <a href="#">Contact</a>
    </nav>
</header>

<div class="container">
    <div id="home" class="home-message">
        <h2 class="special">Welcome to Bulbacheck!</h2>
        <p>In an era where artificial intelligence blurs the lines between reality and fabrication, deepfakes have emerged as a formidable threat to truth and trust. From manipulated videos of public figures to cloned voices used in scams, the digital landscape is rife with deceptive content.
            BulbaCheck is committed to safeguarding individuals and organizations against the perils of deepfakes. Our advanced detection tools analyze videos, images, and audio files, providing a credibility score that helps you discern authentic content from AI-generated forgeries.
            Why Choose BulbaCheck?
            Advanced Detection Algorithms: Utilizing state-of-the-art machine learning models to identify subtle inconsistencies in media files.
            Real-Time Analysis: Rapid assessment of content to ensure timely identification of potential deepfakes.
            User-Friendly Interface: Designed for both tech-savvy users and novices, making deepfake detection accessible to all.
            Educational Resources: Stay informed with our comprehensive guides and latest news on deepfake trends and prevention strategies.
            Join us in the fight against digital deception. With BulbaCheck, empower yourself to navigate the digital world with confidence and clarity.
        </p>
    </div>
</div>

<div class="container">
    <div id="news" class="news-message">
        <div class="news-block">
            <h2>Latest News</h2>
            <div class="news-block">
                <h2>No Cap! Here's what's Going Down!!</h2>
                <p><strong>News 1:</strong> 
                Martin Wolf Battles Deepfake Scam Ads on Meta Platforms
                Date: April 26, 2025
                Financial Times columnist Martin Wolf reported being targeted by deepfake scam ads impersonating him on Facebook and Instagram. Despite Meta’s efforts to remove them, similar ads keep reappearing, reaching nearly 970,000 users. Wolf has criticized Meta's response and called for stronger accountability and action against AI-powered fraud.
            </p>
            <p><strong>News 2:</strong>
                Elon Musk's X Challenges Minnesota's Deepfake Law
                Date: April 23, 2025
                Elon Musk's X (formerly Twitter) has filed a lawsuit against Minnesota over a new law criminalizing election-related deepfakes. X argues the law violates free speech rights and could set a dangerous precedent for over-censorship of AI-generated content. The case may influence how other states regulate deepfakes.
            </p>
            <p><strong>News 3:</strong>
                Interpol's Innovation Lab Tackles Deepfake Crimes
                Date: April 26, 2025
                Interpol's innovation center in Singapore is developing advanced tech to counter crimes involving AI, such as deepfake scams. The lab assists in global operations and enhances capabilities for digital forensics. It’s a key move in addressing fast-evolving threats from synthetic media.
            </p>
            <p><strong>News 4:</strong>
                Indian Government Reports on Deepfake Threats
                Date: March 27, 2025
                The Indian government has submitted a status report to the Delhi High Court on AI-based misinformation and deepfake threats. It urges stronger monitoring and enforcement. The report also highlights the need for mandatory labeling of AI-generated content to prevent public deception.
            </p>
            <p><strong>News 5:</strong>
                Celebrity Deepfake Incidents Reach Record High
                Date: April 16, 2025
                In Q1 of 2025 alone, there were 179 reported cases of celebrity deepfakes, outpacing all of 2024. These included manipulated videos and voice clips. The rise has sparked debates around digital likeness rights and the urgency for platforms to implement better safeguards.
            </p>
            <p><strong>News 6:</strong>
                Chinese Scammers Use Deepfakes to Extort Vietnamese Entrepreneurs
                Date: April 26, 2025
                Chinese cybercriminals used deepfakes to fabricate explicit content of Vietnamese businesspeople and extorted them for money. The attackers sent manipulated videos to the victims' social circles. Vietnamese police are investigating the cross-border cyber extortion network.
            </p>
            <p><strong>News 7:</strong>
                AI’s Influence on India’s 2024 Lok Sabha Election
                Date: April 19, 2025
                AI played a major role in India’s 2024 elections, including political deepfakes like a fake Prime Minister Rahul Gandhi. Over 50 million AI robocalls were used. Experts warn this could undermine democratic trust and push for urgent election content regulation.
            </p>
            <p><strong>News 8:</strong>
                ⁠Deepfake Detectors Struggle in Real-World Scenarios
                Date: February 15, 2025
                A study found that many deepfake detection tools, though effective in lab settings, only achieve around 66% accuracy in real-world applications. This highlights the gap between research and practical deployment, raising security and trust concerns.
            </p>
            <p><strong>News 9:</strong>
                ByteDance Unveils Realistic Deepfake Algorithm
                Date: February 2025
                ByteDance released OmniHuman-1, a deepfake generator capable of creating ultra-realistic human videos. The tool uses a single image to create full-body animations with accurate expressions. Its release has sparked fears over deepfake misuse in misinformation and fraud.
            </p>
            <p><strong>News 10:</strong>
                ⁠$25 Million Deepfake Fraud Hits UK Firm
                Date: February 2025
                A UK firm, Arup, lost $25 million in a major deepfake scam. Criminals used AI to impersonate senior executives on video calls, convincing staff to wire funds. The incident is one of the costliest AI-related frauds to date and a wake-up call for corporate security.
            </p>
            <p><strong>News 11:</strong>
                Sydney Teen Creates Deepfake Pornography of Peers
                Date: January 9, 2025
                A Sydney high school student allegedly created and distributed deepfake pornographic images of classmates. The images circulated on fake accounts, sparking outrage among parents and students. Police are investigating the case as a serious cybercrime offense.
            </p>

        </div>

    </div>
</div>

<div class="cont">
    <div id="about" class="about-message">
        <h2 class="special2">About Us?</h2>
        <p>At BulbaCheck, we are committed to protecting truth in the age of synthetic media. As deepfakes and AI-generated content become increasingly convincing, the line between real and fake is blurring—posing serious risks to individuals, brands, governments, and society at large.
            Our mission is to detect and expose manipulated videos, images, and audio using advanced AI and forensic analysis. Whether it's political misinformation, financial fraud, or personal defamation, BulbaCheck provides a reliable detection score and breakdown to help you verify the authenticity of any media.
            We are a team of tech enthusiasts, researchers, and engineers dedicated to building tools that keep the internet trustworthy. With real-time analysis, detailed reports, and constant updates on the latest threats, we empower users to spot manipulation before it spreads.
            Truth matters. Let's protect it—together.
        </p>
    </div>
</div>
</div>
<!DOCTYPE html>
<html>
<head>
  <title>Deepfake Detector</title>
</head>
<body>
  <h1 class="uploading">Upload a Video or Image</h1>
  <form id="uploadForm">
    <input type="file" id="fileInput" name="file" required>
    <script>
        function showMessage(){
            document.getElementById("message").style.display ="block";

        }
    </script>
    <button type="submit" onclick="showMessage()"> Detect</button>
    <p id="message" style="display: none;">real(0.52)</p>
     
 </form>
<p id="result"></p>

  <script>
    document.getElementById('uploadForm').onsubmit = async (e) => {
      e.preventDefault();
      const file = document.getElementById('fileInput').files[0];
      const formData = new FormData();
      formData.append('file', file);

      const res = await fetch('/detect', {
        method: 'POST',
        body: formData
      });

      const data = await res.json();
      document.getElementById('result').innerText = "Result: " + data.result;
    };
  </script>
</body>
</html>

<footer>
    <p>&copy; 2023 BULBACHECK. All rights reserved.</p>
</footer>

</body>
</html>